{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP pour l’analyse de critiques de films\n",
    "\n",
    "## Contexte du projet\n",
    "\n",
    "En règle générale, le nombre d'avis sur un film peu être important et par conséquent le temps de lecture de chaque commentaire peut être une tâche lourde. Alors comment déterminer de manière rapide si un film a eu du succès auprès des spectateurs (ou pas) ? Dans ce contexte, l’idée du projet est d’utiliser des algorithmes d'apprentissage automatique pour la tâche d'analyse de sentiment des spectateurs via leur critique.\n",
    "\n",
    "Tout d’abord, il sera question que récupérer les données directement du site d’Allociné. En d’autres termes, nous allons scraper les pages qui nous intéressent sur ce site à savoir les critiques des personnes pour le film Inception et Sonic 2.\n",
    "\n",
    "En navigant sur la page des critiques, vous vous apercevrez que seules deux types d’information ici nous intéresse : la note du spectateur ainsi que son avis. Pourquoi la note ? Parce que nous allons entraîner un modèle de type supervisé et plus précisément un classifieur et donc la note va nous aider à récupérer la classe pour étiqueter le commentaire. Pour cela, nous considérerons qu’une note au-dessus de 3 est considérée comme satisfaisante. Sinon, l’avis est négatif. Ici, nous avons donc réduit le problème à une classification binaire.\n",
    "\n",
    "## Etape 1 : Web Scraping des données d'avis de spectateurs\n",
    "\n",
    "Le web scrapping à été réalisé dans le script 'web_scraping.py' et les résultats sont sous forme de dataframes exporté grâce à joblib dans le fichier 'dataframes'\n",
    "\n",
    "## Etape 2 : Préparation des données\n",
    "\n",
    "Ayant maintenant nos jeux de données, il faut les préparer afin de pouvoir modéliser notre analyse de sentiments. Pour cela nous allons faire appel à plusieurs techniques :\n",
    "\n",
    "- Des expressions régulières pour retirer les bruits (ponctuation, etc.) des commentaires.\n",
    "- Du NLP pour tokeniser et réduire le corpus de chaque commentaire (afin par exemple de ne garder que les mots importants via les stopwords)\n",
    "  - Des sacs de mots afin de « transformer » nos mots en nombres qui pourront alors être exploités dans un algorithme de Machine learning\n",
    "  \n",
    "*Les commentaires seront filtrés à leur essentiel.*\n",
    "\n",
    "### *Import des librairies :*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from french_lefff_lemmatizer.french_lefff_lemmatizer import FrenchLefffLemmatizer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Import des jeux de données :*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sonic = joblib.load('dataframes')['sonic2']\n",
    "df_inception = joblib.load('dataframes')['inception']\n",
    "\n",
    "df = pd.concat([df_sonic, df_inception])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Commentaires</th>\n",
       "      <th>Notes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\nune bonne suite pour les aventures de sonic ...</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\nCette suite de sonic est incroyable !Le fan ...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\nTrès bon film ont retrouve ce qui fait l’esp...</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\nSuper film de ouf, le fait que Knuckles soit...</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\nMalgré deux nouveaux personnages de l'univer...</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Commentaires Notes\n",
       "0  \\nune bonne suite pour les aventures de sonic ...   4.0\n",
       "1  \\nCette suite de sonic est incroyable !Le fan ...   5.0\n",
       "2  \\nTrès bon film ont retrouve ce qui fait l’esp...   4.5\n",
       "3  \\nSuper film de ouf, le fait que Knuckles soit...   4.0\n",
       "4  \\nMalgré deux nouveaux personnages de l'univer...   3.0"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On remarque de suite que les commentaires ne sont pas encore bien mis en forme, il faudra arranger cela par la suite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Commentaires    0\n",
       "Notes           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aucune valeur nulle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7350, 2)"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On a un total de 7350 commentaires dans notre dataset\n",
    "\n",
    "### *Gestion du bruit des commentaires :*\n",
    "\n",
    "On définit une fonction pour supprimer le bruit :\n",
    "- Suppresion des caractères spéciaux\n",
    "- Désaccentuation\n",
    "- Tout passer en minuscule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_text(df, content_field):\n",
    "    df[content_field] = df[content_field].str.replace(r\"http\\S+\", \"\")\n",
    "    df[content_field] = df[content_field].str.replace(r\"http\", \"\")\n",
    "    df[content_field] = df[content_field].str.replace(r\"@\\S+\", \"\")\n",
    "    df[content_field] = df[content_field].str.replace(r\"[0-9(),!?@\\'\\:\\.\\/\\^\\-\\`\\\"\\_\\n]\", \" \")\n",
    "    df[content_field] = df[content_field].str.replace(r\"@\", \"at\")\n",
    "    df[content_field] = df[content_field].str.normalize('NFKD').str.encode('ascii', errors='ignore').str.decode('utf-8')\n",
    "    df[content_field] = df[content_field].str.lower()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5550/1153927108.py:2: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df[content_field] = df[content_field].str.replace(r\"http\\S+\", \"\")\n",
      "/tmp/ipykernel_5550/1153927108.py:4: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df[content_field] = df[content_field].str.replace(r\"@\\S+\", \"\")\n",
      "/tmp/ipykernel_5550/1153927108.py:5: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df[content_field] = df[content_field].str.replace(r\"[0-9(),!?@\\'\\:\\.\\/\\^\\-\\`\\\"\\_\\n]\", \" \")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Commentaires</th>\n",
       "      <th>Notes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>une bonne suite pour les aventures de sonic a...</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cette suite de sonic est incroyable  le fan q...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tres bon film ont retrouve ce qui fait lespri...</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>super film de ouf  le fait que knuckles soit ...</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>malgre deux nouveaux personnages de l univers...</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Commentaires Notes\n",
       "0   une bonne suite pour les aventures de sonic a...   4.0\n",
       "1   cette suite de sonic est incroyable  le fan q...   5.0\n",
       "2   tres bon film ont retrouve ce qui fait lespri...   4.5\n",
       "3   super film de ouf  le fait que knuckles soit ...   4.0\n",
       "4   malgre deux nouveaux personnages de l univers...   3.0"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "standardize_text(df, 'Commentaires')\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Séparation du jeu de données :*\n",
    "\n",
    "Les prochaines étapes de préparation ne doivent s'appliquer qu'au jeu d'entraînement, il nous faut garder un jeu de test intact."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notre jeu d'entrainement contient 5880 commentaires et celui de test en contient 1470\n"
     ]
    }
   ],
   "source": [
    "y = df['Notes']\n",
    "X = df.drop('Notes', axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Notre jeu d'entrainement contient {X_train.shape[0]} commentaires et celui de test en contient {X_test.shape[0]}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Tokenisation :*\n",
    "\n",
    "Le but désormais est de constituer notre *corpus* (collection de commentaires) traité, c'est à dire sans *'stop words'* et *lemmatisé*.\n",
    "\n",
    "- Les *'stop words'* sont les mots qui n'apportent aucune information.\n",
    "\n",
    "- La *lematisation* consiste à réduire un mot à sa forme de base (ex : mangea devient manger). \n",
    "\n",
    "On utilisera la librarie `FrenchLefffLemmatizer` developpée par Claude Colombe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voici la liste des stopwords de la langue française : ['au', 'aux', 'avec', 'ce', 'ces', 'dans', 'de', 'des', 'du', 'elle', 'en', 'et', 'eux', 'il', 'ils', 'je', 'la', 'le', 'les', 'leur', 'lui', 'ma', 'mais', 'me', 'même', 'mes', 'moi', 'mon', 'ne', 'nos', 'notre', 'nous', 'on', 'ou', 'par', 'pas', 'pour', 'qu', 'que', 'qui', 'sa', 'se', 'ses', 'son', 'sur', 'ta', 'te', 'tes', 'toi', 'ton', 'tu', 'un', 'une', 'vos', 'votre', 'vous', 'c', 'd', 'j', 'l', 'à', 'm', 'n', 's', 't', 'y', 'été', 'étée', 'étées', 'étés', 'étant', 'étante', 'étants', 'étantes', 'suis', 'es', 'est', 'sommes', 'êtes', 'sont', 'serai', 'seras', 'sera', 'serons', 'serez', 'seront', 'serais', 'serait', 'serions', 'seriez', 'seraient', 'étais', 'était', 'étions', 'étiez', 'étaient', 'fus', 'fut', 'fûmes', 'fûtes', 'furent', 'sois', 'soit', 'soyons', 'soyez', 'soient', 'fusse', 'fusses', 'fût', 'fussions', 'fussiez', 'fussent', 'ayant', 'ayante', 'ayantes', 'ayants', 'eu', 'eue', 'eues', 'eus', 'ai', 'as', 'avons', 'avez', 'ont', 'aurai', 'auras', 'aura', 'aurons', 'aurez', 'auront', 'aurais', 'aurait', 'aurions', 'auriez', 'auraient', 'avais', 'avait', 'avions', 'aviez', 'avaient', 'eut', 'eûmes', 'eûtes', 'eurent', 'aie', 'aies', 'ait', 'ayons', 'ayez', 'aient', 'eusse', 'eusses', 'eût', 'eussions', 'eussiez', 'eussent']\n"
     ]
    }
   ],
   "source": [
    "print(f\"Voici la liste des stopwords de la langue française : {stopwords.words('french')}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On définit note fonction créer notre corpus :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_corpus(df, content_field):\n",
    "    lemmatizer = FrenchLefffLemmatizer()\n",
    "    corpus = []\n",
    "    for i, row in df.iterrows():\n",
    "        message = row.item()\n",
    "        message = message.split()                                   \n",
    "        message =[word for word in message if not word in set(stopwords.words('french'))]\n",
    "        message = [lemmatizer.lemmatize(word) for word in message]\n",
    "        message = ' '.join(message)\n",
    "        corpus.append(message)\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = make_corpus(X_train, 'Commentaires') #Temps d'éxecution : ~30-45s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quelques exemple de commentaires filtrés à l'essentiel : \n",
      "\n",
      "christopher nolan signe encore excellent film effet speciaux enormes bande aussi acteur parfaitement bien choisis pris dedans debut a fin minute ennuie merveilleux\n",
      "\n",
      "thriller film action a tres haut niveau grand nolan scenario assez original faire film film complet excellent voit plus acteur jouer leurs personnage seul bemol quelques longueur idee tres develloppee quelques scenes rappelle shutter island scorcese aussi leonardo dicaprio etait aussi tres bon film allez voir regretterez\n",
      "\n",
      "enorme scenario effet speciaux a voir absolument contre tentez distraire autre chose film pendant projection sou peine etre largue intrigue a sortie seance quel plaisir quelles impression beau cinema\n",
      "\n",
      "rien compris desole vraiment rien si quelqu veut bien expliquer\n"
     ]
    }
   ],
   "source": [
    "print(f\"Quelques exemple de commentaires filtrés à l'essentiel : \\n\\n{corpus[456]}\\n\\n{corpus[1456]}\\n\\n{corpus[25]}\\n\\n{corpus[3569]}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les commentaires sont donc maintenant bien traités, on peut passer à la prochaine étape.\n",
    "\n",
    "## Etape 3 : Préparation des libellés\n",
    "\n",
    "Jusque là, à chaque commentaire est associé une note de 1 à 5 et non une classe binaire. Il nous faut donc convertir nos notes en : 1 pour avis positif et 0 : pour avis négatif\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.float64'> <class 'numpy.float64'>\n"
     ]
    }
   ],
   "source": [
    "y_train = y_train.astype('float')\n",
    "y_test = y_test.astype('float')\n",
    "print(type(y_train[0]), type(y_test[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "def codage_libelle(data):\n",
    "    \"\"\"Convertit les notes en 0 ou 1 selon s'il s'agit d'un avis positif ou négatif\"\"\"\n",
    "    positif = data >= 3\n",
    "    negatif = data < 3\n",
    "    data[positif] = 1\n",
    "    data[negatif] = 0\n",
    "    data = data.astype('int')\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_train, y_test = codage_libelle(y_train), codage_libelle(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    4971\n",
       "0     909\n",
       "Name: Notes, dtype: int64"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On remarque tout de suite que notre dataset n'est pas équilibré, on a 5 fois plus d'avis positifs que négatifs. Pour y remédier on pourrait recourir au procédé de data augmentation.\n",
    "\n",
    "## Etape 4 : Finalisation de nos jeux de données\n",
    "\n",
    "Les données sont presque prêtes mais nos commentaires qui sont maintenant sous forme de sac de mots doivent être convertis en nombre. Pour cela, il va falloir vectoriser nos mots (technique des sacs de mots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(ngram_range=(1, 3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c52c0416b2dd799a5cb6470f4983ed131454af8dda684e12ae493944f88c50f3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
